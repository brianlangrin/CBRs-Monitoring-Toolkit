{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f80da2-3aea-4a75-8bf3-767be9379301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyvis  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99f50919-1495-412f-ab02-ad7f6489a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0b634a4-617a-4ef7-a224-26d0551e412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # For clearing variables and setting working directory \n",
    "import numpy as np  \n",
    "import pandas as pd  # For data manipulation\n",
    "import matplotlib.pyplot as plt  \n",
    "import networkx as nx    # NetworkX is a widely used package for graph operations, similar to igraph in R.\n",
    "from pyvis.network import Network  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2310f7f6-7dc2-4778-a817-343eecd3ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output  # Clear console\n",
    "clear_output(wait=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b3b14a-6b38-46a8-92b9-1289f0aed8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: '%.0f' % x) #Turning off scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b63c3df-1dd4-4b66-9765-e4e779873292",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"C:\\\\Users\\\\blang\\\\OneDrive\\\\Desktop\\\\RProject with dummy data\")  # sets the working directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3735ae-4d47-44ff-8592-d2938751c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into a DataFrame\n",
    "transparency = pd.read_csv(\"transparency.csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a943e513-534f-4910-bf4d-209926efa25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NA (missing values) with empty strings\n",
    "transparency = transparency.replace({np.nan: ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51d0b336-39b2-4dd0-9dc5-29628cf1ac38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Code speriod1 speriod2 speriod3 speriod4 speriod5 chperiod1 chperiod2  \\\n",
      "0   AE       68       69       70       70       66         0         1   \n",
      "1   AF        8        8       12       11       15         0         0   \n",
      "2   AL       33       31       33       36       39         0        -1   \n",
      "3   AM       34       36       37       35       33         0         1   \n",
      "4   AO       22       23       19       15       18         0         1   \n",
      "\n",
      "  chperiod3 chperiod4 chperiod5  \n",
      "0         1         0        -1  \n",
      "1         1        -1         1  \n",
      "2         1         1         1  \n",
      "3         1        -1        -1  \n",
      "4        -1        -1         1  \n"
     ]
    }
   ],
   "source": [
    "# Ensure the DataFrame is properly loaded\n",
    "print(transparency.head())  # Optional: Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9d1ceba-948c-4b95-8237-a71f56b0ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments = pd.read_csv(\"data4-3.csv\")  # Note: Ensure the data file is in the working directory set earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbee7710-fabc-49cd-86c1-05672b6f55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments1 = payments.copy()  # Create a copy of the dataframe  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c556737d-2aeb-4721-877c-5714061f7539",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Month', 'Initial Ordering BIC8', 'Initial Ordering BIC8 name',\n",
      "       'Initial Ordering Country', 'BIC8', 'BIC8 name', 'BIC8 Country',\n",
      "       'Counterparty BIC8', 'Counterparty BIC8 name',\n",
      "       'Counterparty BIC8 Country', 'End Beneficiary BIC8',\n",
      "       'End Beneficiary BIC8 name', 'End Beneficiary Country', 'Message Type',\n",
      "       'Currency', 'Net.USD.Amount', 'Transactions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(payments1.columns) # Ensure all columns are in the right format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09754654-bdf5-494d-a3de-8d606906c4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year', 'Month', 'Initial.Ordering.BIC8', 'Initial.Ordering.BIC8.name',\n",
      "       'Initial.Ordering.Country', 'BIC8', 'BIC8.name', 'BIC8.Country',\n",
      "       'Counterparty.BIC8', 'Counterparty.BIC8.name',\n",
      "       'Counterparty.BIC8.Country', 'End.Beneficiary.BIC8',\n",
      "       'End.Beneficiary.BIC8.name', 'End.Beneficiary.Country', 'Message.Type',\n",
      "       'Currency', 'Net.USD.Amount', 'Transactions'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Replace spaces with dots in all column names of the DataFrame\n",
    "payments1.columns = payments1.columns.str.replace(' ', '.', regex=False)\n",
    "\n",
    "# Check the updated column names\n",
    "print(payments1.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee8ab8a6-7ba6-4c0a-87a8-f4ba90c0fada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the column name is slightly different or has leading/trailing spaces, rename it\n",
    "payments1.rename(columns=lambda x: x.strip(), inplace=True)  # Removes leading/trailing spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bfc0627-b6ec-41a2-a77c-2bec6cff92dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "payments1.columns = payments1.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc522d67-2250-48b9-b144-e296d1c42d7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List of columns to convert to string\n",
    "string_columns = [\n",
    "    \"Year\", \"Month\", \"Initial.Ordering.BIC8\", \"Initial.Ordering.BIC8.name\",\n",
    "    \"Initial.Ordering.Country\", \"BIC8\", \"BIC8.name\", \"BIC8.Country\",\n",
    "    \"Counterparty.BIC8\", \"Counterparty.BIC8.name\", \"Counterparty.BIC8.Country\",\n",
    "    \"End.Beneficiary.BIC8\", \"End.Beneficiary.BIC8.name\", \"End.Beneficiary.Country\",\n",
    "    \"Message.Type\", \"Currency\"\n",
    "]\n",
    "\n",
    "# Convert columns to string if they exist in the DataFrame\n",
    "for col in string_columns:\n",
    "    if col in payments1.columns:\n",
    "        payments1[col] = payments1[col].astype(str)\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' does not exist in the DataFrame.\") # Adds a warning message for any columns\n",
    "                                                                           # that are missing, making it easier to debug.\n",
    "\n",
    "# List of columns to convert to numeric\n",
    "numeric_columns = [\"Net.USD.Amount\", \"Transactions\"]\n",
    "\n",
    "# Convert columns to numeric if they exist in the DataFrame\n",
    "for col in numeric_columns:\n",
    "    if col in payments1.columns:\n",
    "        payments1[col] = pd.to_numeric(payments1[col], errors='coerce')\n",
    "    else:\n",
    "        print(f\"Warning: Column '{col}' does not exist in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c297e4d-af00-47dd-8deb-27cf5425f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Month', 'Initial.Ordering.BIC8', 'Initial.Ordering.BIC8.name', 'Initial.Ordering.Country', 'BIC8', 'BIC8.name', 'BIC8.Country', 'Counterparty.BIC8', 'Counterparty.BIC8.name', 'Counterparty.BIC8.Country', 'End.Beneficiary.BIC8', 'End.Beneficiary.BIC8.name', 'End.Beneficiary.Country', 'Message.Type', 'Currency', 'Net.USD.Amount', 'Transactions']\n"
     ]
    }
   ],
   "source": [
    "print(payments1.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c40d624f-ae14-442c-b90f-0b25c019a9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a variable \"flow\", which will be used to determine \n",
    "# whether a transaction was an inflow or outflow\n",
    "payments1[\"flow\"] = 0  # Initialize the \"flow\" column to 0\n",
    "\n",
    "# Update \"flow\" column based on conditions\n",
    "payments1.loc[payments1[\"Initial.Ordering.BIC8\"] == payments1[\"BIC8\"], \"flow\"] = 1\n",
    "payments1.loc[payments1[\"End.Beneficiary.BIC8\"] == payments1[\"BIC8\"], \"flow\"] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cfbc722-c478-4ece-8460-f050f17a0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = payments1.copy()  # Create the final dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5efcbed-f6c0-47ce-8b26-b0bffdc635c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year Month Initial.Ordering.BIC8 Initial.Ordering.BIC8.name  \\\n",
      "0  2015   Jul              BNKAXXYY                        nan   \n",
      "1  2015   Jul              BNKAXXYY                        nan   \n",
      "2  2015   Jul              BNKCXXYY                        nan   \n",
      "3  2015   Jul              BNKDXXYY                        nan   \n",
      "4  2015   Jul              BNKDXXYY                        nan   \n",
      "\n",
      "  Initial.Ordering.Country      BIC8 BIC8.name BIC8.Country Counterparty.BIC8  \\\n",
      "0                       XX  BNKAXXYY       nan           XX              GLOB   \n",
      "1                       XX  BNKAXXYY       nan           XX              GLOC   \n",
      "2                       XX  BNKCXXYY       nan           XX              GLOH   \n",
      "3                       XX  BNKDXXYY       nan           XX              GLOK   \n",
      "4                       XX  BNKDXXYY       nan           XX              GLOK   \n",
      "\n",
      "  Counterparty.BIC8.name Counterparty.BIC8.Country End.Beneficiary.BIC8  \\\n",
      "0                    nan                        US                 GLOK   \n",
      "1                    nan                        US                 GLOK   \n",
      "2                    nan                        DE                 GLOK   \n",
      "3                    nan                        IN                 GLOK   \n",
      "4                    nan                        US                 GLOK   \n",
      "\n",
      "  End.Beneficiary.BIC8.name End.Beneficiary.Country Message.Type Currency  \\\n",
      "0                       nan                      US        MT103      USD   \n",
      "1                       nan                      TW        MT103      USD   \n",
      "2                       nan                      TW        MT103      USD   \n",
      "3                       nan                      IN        MT700      USD   \n",
      "4                       nan                      US        MT103      USD   \n",
      "\n",
      "   Net.USD.Amount  Transactions  flow  \n",
      "0          500000            10     1  \n",
      "1           16000             1     1  \n",
      "2           10000             1     1  \n",
      "3           27238             1     1  \n",
      "4         6560442           130     1  \n"
     ]
    }
   ],
   "source": [
    "# Optional: Preview the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bef50b67-bfaa-4ee8-90ec-5709b3ed6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime  \n",
    "from datetime import date  # Import the necessary library\n",
    "today_date = date.today()  # Define today's date"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ace5c62-f3e8-410b-b147-7f53e8790a5d",
   "metadata": {},
   "source": [
    "# -------------------------------------- #  \n",
    "#           SETTINGS TOGGLE MENU         #  \n",
    "# -------------------------------------- #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "248ff773-7d21-495b-83ce-9b6099eaa683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Today's date  \n",
    "date = datetime.date.today()  # Gets today's date  \n",
    "\n",
    "# 2. Pathway length toggle  \n",
    "pathway_length_toggle = \"r\"  # 'r' for correspondent relationships, 'e' for endpoint, 'f' for full  \n",
    "\n",
    "# 3. System or individual view  \n",
    "system_or_individual_view = \"s\"  # 's' for system or 'b' for bank  \n",
    "\n",
    "# 4. Country or institution view  \n",
    "country_or_institution_view = \"c\"  # 'c' for country or 'i' for institution  \n",
    "\n",
    "# 5. Color using index  \n",
    "color_using_index = \"yes\"  # 'yes' or 'no'; requires an additional file if 'yes'  \n",
    "\n",
    "# 6. Selected bank  \n",
    "selected_bank = \"BNKAXXYY\"  # Needs to be a BIC 8-letter code  \n",
    "\n",
    "# 7. Selected country  \n",
    "selected_country = \"XX\"  # Needs to be an ISO 2-letter code  \n",
    "\n",
    "# 8. Selected period  \n",
    "selected_period = 6  # Selects the period (1-6) for which the map will be generated  \n",
    "\n",
    "# 9. Selected quarter  \n",
    "selected_quarter = \"y\"  # Selects the quarter (1-4, or 'y' for entire year)  \n",
    "\n",
    "# 10. Currency  \n",
    "currency = \"USD\"  # Needs to be a 3-letter currency ticker; use 'All' if not specifying a single currency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea10e043-220a-4c76-a1f7-5c6ed97f6b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2025-03-03\n",
      "Pathway Length Toggle: r\n",
      "System or Individual View: s\n",
      "Country or Institution View: c\n",
      "Color Using Index: yes\n",
      "Selected Bank: BNKAXXYY\n",
      "Selected Country: XX\n",
      "Selected Period: 6\n",
      "Selected Quarter: y\n",
      "Currency: USD\n"
     ]
    }
   ],
   "source": [
    "# Print the current settings for reference (optional)\n",
    "print(\"Date:\", today_date)\n",
    "print(\"Pathway Length Toggle:\", pathway_length_toggle)\n",
    "print(\"System or Individual View:\", system_or_individual_view)\n",
    "print(\"Country or Institution View:\", country_or_institution_view)\n",
    "print(\"Color Using Index:\", color_using_index)\n",
    "print(\"Selected Bank:\", selected_bank)\n",
    "print(\"Selected Country:\", selected_country)\n",
    "print(\"Selected Period:\", selected_period)\n",
    "print(\"Selected Quarter:\", selected_quarter)\n",
    "print(\"Currency:\", currency)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5dadd6d1-44e8-44dc-83a5-abb9bbb21cfa",
   "metadata": {},
   "source": [
    "# -----------------------  \n",
    "# FILTER CURRENCY:  \n",
    "# -----------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "349c8569-9c70-48fd-ab7e-5f2d8eb032a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on currency  \n",
    "if currency != \"All\":  \n",
    "    dataframe_currency = df[df['Currency'] == currency]  \n",
    "else:  \n",
    "    dataframe_currency = df  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12da401-1dfd-4cea-82d2-6b589bfd33a8",
   "metadata": {},
   "source": [
    "# -----------------------  \n",
    "# FILTER INSTITUTION  \n",
    "# -----------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db346cf0-f125-4668-8c87-d24bce3217c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame based on the selected bank if individual view is selected  \n",
    "# If system_or_individual_view is \"b\", the DataFrame is filtered to include only rows where 'BIC8' matches the selected_bank.\n",
    "if system_or_individual_view == \"b\":  \n",
    "    dataframe_currency = dataframe_currency[dataframe_currency['BIC8'] == selected_bank]  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "636bbb9f-4c87-4350-8f2e-6cd3c0366c4b",
   "metadata": {},
   "source": [
    "# -----------------------  \n",
    "# FILTER PERIOD:  \n",
    "# -----------------------  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8b3054d-a98a-4e14-89c0-01e13c3eba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually, the data is in the Month-YY format (e.g. \"Jan-12\")  \n",
    "# Here we set years for the selected periods  \n",
    "year1 = \"2015\"  \n",
    "year2 = \"2016\"  \n",
    "year3 = \"2015\"  \n",
    "year4 = \"2016\"  \n",
    "year5 = \"2015\"  \n",
    "year6 = \"2016\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "237d5afd-db76-4639-bf3e-161b226923f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER PERIOD:\n",
    "# Function to aggregate data by year and quarter\n",
    "def aggregate_by_period(df, year, quarter):\n",
    "    # Filter data by year\n",
    "    df_year = df[df['Year'] == year]\n",
    "    \n",
    "    # Filter by quarter or entire year\n",
    "    if quarter == \"y\":\n",
    "        return df_year  # Entire year\n",
    "    elif quarter in [1, \"1\"]:\n",
    "        return df_year[df_year['Month'].isin([\"Jan\", \"Feb\", \"Mar\"])]\n",
    "    elif quarter in [2, \"2\"]:\n",
    "        return df_year[df_year['Month'].isin([\"Apr\", \"May\", \"Jun\"])]\n",
    "    elif quarter in [3, \"3\"]:\n",
    "        return df_year[df_year['Month'].isin([\"Jul\", \"Aug\", \"Sep\"])]\n",
    "    elif quarter in [4, \"4\"]:\n",
    "        return df_year[df_year['Month'].isin([\"Oct\", \"Nov\", \"Dec\"])]\n",
    "    else:\n",
    "        return pd.DataFrame()   # Return an empty DataFrame if quarter is invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "310c2902-0c6b-4b2d-8da0-da2dd51af7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate data for each period\n",
    "# Separate DataFrames (df1 through df6) are created for each year and quarter combination.\n",
    "df1 = aggregate_by_period(dataframe_currency, year1, selected_quarter)\n",
    "df2 = aggregate_by_period(dataframe_currency, year2, selected_quarter)\n",
    "df3 = aggregate_by_period(dataframe_currency, year3, selected_quarter)\n",
    "df4 = aggregate_by_period(dataframe_currency, year4, selected_quarter)\n",
    "df5 = aggregate_by_period(dataframe_currency, year5, selected_quarter)\n",
    "df6 = aggregate_by_period(dataframe_currency, year6, selected_quarter)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c19cd59-7a80-4c08-9dce-f83facaac214",
   "metadata": {},
   "source": [
    "BIND GRAPHS: handles the binding of graphs and breaks transactions into bilateral transfers depending on the value of pathway_length_toggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b4be148-8351-4cb0-8c63-f2e2d50f8744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for correspondent banks only (pathway_length_toggle == \"r\")\n",
    "# Splits the transactions into inflows and outflows, rearranges the columns, and concatenates the two subsets.\n",
    "def bind_graphs_correspondent(df):\n",
    "    graph1 = df[df['flow'] == 1][[\"BIC8\", \"BIC8.Country\", \"Counterparty.BIC8\", \"Counterparty.BIC8.Country\", \"Currency\", \"Net.USD.Amount\", \"Transactions\"]]\n",
    "    graph1.columns = [\"from\", \"from.country\", \"to\", \"to.country\", \"currency\", \"weight\", \"volume\"]\n",
    "\n",
    "    graph2 = df[df['flow'] == -1][[\"Counterparty.BIC8\", \"Counterparty.BIC8.Country\", \"BIC8\", \"BIC8.Country\", \"Currency\", \"Net.USD.Amount\", \"Transactions\"]]\n",
    "    graph2.columns = [\"from\", \"from.country\", \"to\", \"to.country\", \"currency\", \"weight\", \"volume\"]\n",
    "\n",
    "    graph = pd.concat([graph1, graph2], ignore_index=True)\n",
    "    graph = graph[[\"from\", \"to\", \"weight\", \"volume\", \"currency\", \"from.country\", \"to.country\"]]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "272ab1e2-80d6-410d-871d-438f032d2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for endpoints only (pathway_length_toggle == \"e\")\n",
    "# Directly maps the Initial.Ordering.BIC8 to End.Beneficiary.BIC8, creating a graph based only on these endpoints.\n",
    "def bind_graphs_endpoints(df):\n",
    "    graph = df[[\"Initial.Ordering.BIC8\", \"Initial.Ordering.Country\", \"End.Beneficiary.BIC8\", \"End.Beneficiary.Country\", \"Currency\", \"Net.USD.Amount\", \"Transactions\"]]\n",
    "    graph.columns = [\"from\", \"from.country\", \"to\", \"to.country\", \"currency\", \"weight\", \"volume\"]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbb562fe-fd66-46ea-9080-f610f2a9d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for full payment chain (pathway_length_toggle == \"f\")\n",
    "# Combines the correspondent (Initial.Ordering.BIC8 -> Counterparty.BIC8) and endpoint transactions (Counterparty.BIC8 -> End.Beneficiary.BIC8) into a single graph.\n",
    "def bind_graphs_full_chain(df):\n",
    "    graph1 = df[[\"Initial.Ordering.BIC8\", \"Initial.Ordering.Country\", \"Counterparty.BIC8\", \"Counterparty.BIC8.Country\", \"Currency\", \"Net.USD.Amount\", \"Transactions\"]]\n",
    "    graph1.columns = [\"from\", \"from.country\", \"to\", \"to.country\", \"currency\", \"weight\", \"volume\"]\n",
    "\n",
    "    graph2 = df[[\"Counterparty.BIC8\", \"Counterparty.BIC8.Country\", \"End.Beneficiary.BIC8\", \"End.Beneficiary.Country\", \"Currency\", \"Net.USD.Amount\", \"Transactions\"]]\n",
    "    graph2.columns = [\"from\", \"from.country\", \"to\", \"to.country\", \"currency\", \"weight\", \"volume\"]\n",
    "\n",
    "    graph = pd.concat([graph1, graph2], ignore_index=True)\n",
    "    graph = graph[[\"from\", \"to\", \"weight\", \"volume\", \"currency\", \"from.country\", \"to.country\"]]\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6682aed-07a2-4e59-9d57-8d9e60bf4892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply functions based on pathway_length_toggle\n",
    "# Column Mapping: The columns are renamed and rearranged to match the desired format for each graph type.\n",
    "if pathway_length_toggle == \"r\":\n",
    "    graphm1 = bind_graphs_correspondent(df1)\n",
    "    graphm2 = bind_graphs_correspondent(df2)\n",
    "    graphm3 = bind_graphs_correspondent(df3)\n",
    "    graphm4 = bind_graphs_correspondent(df4)\n",
    "    graphm5 = bind_graphs_correspondent(df5)\n",
    "    graphm6 = bind_graphs_correspondent(df6)\n",
    "\n",
    "elif pathway_length_toggle == \"e\":\n",
    "    graphm1 = bind_graphs_endpoints(df1)\n",
    "    graphm2 = bind_graphs_endpoints(df2)\n",
    "    graphm3 = bind_graphs_endpoints(df3)\n",
    "    graphm4 = bind_graphs_endpoints(df4)\n",
    "    graphm5 = bind_graphs_endpoints(df5)\n",
    "    graphm6 = bind_graphs_endpoints(df6)\n",
    "\n",
    "elif pathway_length_toggle == \"f\":\n",
    "    graphm1 = bind_graphs_full_chain(df1)\n",
    "    graphm2 = bind_graphs_full_chain(df2)\n",
    "    graphm3 = bind_graphs_full_chain(df3)\n",
    "    graphm4 = bind_graphs_full_chain(df4)\n",
    "    graphm5 = bind_graphs_full_chain(df5)\n",
    "    graphm6 = bind_graphs_full_chain(df6)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "756af294-fff1-4257-90ab-05360130575e",
   "metadata": {},
   "source": [
    "FINALIZE GRAPH:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90908c20-7e4c-4c82-bc6e-ab10be901226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_graph(graph):\n",
    "    # Remove rows where the from or to columns contain missing values (NaN).\n",
    "    graph = graph.dropna(subset=[\"from\", \"to\"])\n",
    "    \n",
    "    # Ensure correct data types for columns\n",
    "    # Columns from and to are converted to strings using .astype(str)\n",
    "    graph[\"from\"] = graph[\"from\"].astype(str)\n",
    "    graph[\"to\"] = graph[\"to\"].astype(str)\n",
    "    # Columns weight and volume are converted to numeric values using pd.to_numeric(). \n",
    "    # If there are invalid numeric values, they will be set to NaN due to errors=\"coerce\".\n",
    "    graph[\"weight\"] = pd.to_numeric(graph[\"weight\"], errors=\"coerce\")\n",
    "    graph[\"volume\"] = pd.to_numeric(graph[\"volume\"], errors=\"coerce\")\n",
    "    \n",
    "    # Remove circular flows (e.g., Bank X --> Bank X) where the from and to columns are equal\n",
    "    graph = graph[graph[\"from\"] != graph[\"to\"]]\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2eee8728-a5b5-4b44-a177-47e17930c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each graph\n",
    "graphm1 = finalize_graph(graphm1)\n",
    "graphm2 = finalize_graph(graphm2)\n",
    "graphm3 = finalize_graph(graphm3)\n",
    "graphm4 = finalize_graph(graphm4)\n",
    "graphm5 = finalize_graph(graphm5)\n",
    "graphm6 = finalize_graph(graphm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0166208-053e-48f3-a745-5943d78fe14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs = [graphm1, graphm2, graphm3, graphm4, graphm5, graphm6]\n",
    "\n",
    "#for i in range(len(graphs)):\n",
    "#    graphs[i] = finalize_graph(graphs[i])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "835359cf-c216-44e6-abbe-47bfae2ae200",
   "metadata": {},
   "source": [
    "Aggregation:The groupby() method is used for both aggregation functions. For institution-based aggregation, we group by from and to columns, and for country-based aggregation, we group by from.country and to.country.\n",
    "The sum() function computes the total weight for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4fa0429-413f-41f4-83cf-2df4aef35321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Institution-based aggregation of flows\n",
    "def graggregate(graph):\n",
    "    # Group by 'from' and 'to' and sum the 'weight'\n",
    "    graph_agg = graph.groupby(['from', 'to'], as_index=False).agg({'weight': 'sum'})\n",
    "    # Ensure data types are consistent\n",
    "    graph_agg['from'] = graph_agg['from'].astype(str)\n",
    "    graph_agg['to'] = graph_agg['to'].astype(str)\n",
    "    graph_agg['weight'] = graph_agg['weight'].astype(float)\n",
    "    return graph_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10bdbb71-c5fe-4fde-8446-c166b45692d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country-based aggregation of flows\n",
    "def graggregate_country(graph):\n",
    "    # Group by 'from.country' and 'to.country' and sum the 'weight'\n",
    "    graph_agg = graph.groupby(['from.country', 'to.country'], as_index=False).agg({'weight': 'sum'})\n",
    "    # Rename columns\n",
    "    graph_agg.columns = ['from', 'to', 'weight']\n",
    "    # Ensure data types are consistent\n",
    "    graph_agg['from'] = graph_agg['from'].astype(str)\n",
    "    graph_agg['to'] = graph_agg['to'].astype(str)\n",
    "    graph_agg['weight'] = graph_agg['weight'].astype(float)\n",
    "    # Remove circular flows\n",
    "    graph_agg = graph_agg[graph_agg['from'] != graph_agg['to']]\n",
    "    return graph_agg"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e44312c6-8970-45ea-ae2b-85f0b38884c0",
   "metadata": {},
   "source": [
    "Column Naming: After aggregation, column names are set accordingly, especially in the country-based aggregation function where we explicitly rename columns after aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5cf4392-6e45-4d77-b7cc-72e32fb60a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply aggregation based on the toggle\n",
    "if country_or_institution_view == \"i\":  # Institution-based\n",
    "    grapha1 = graggregate(graphm1)\n",
    "    grapha2 = graggregate(graphm2)\n",
    "    grapha3 = graggregate(graphm3)\n",
    "    grapha4 = graggregate(graphm4)\n",
    "    grapha5 = graggregate(graphm5)\n",
    "    grapha6 = graggregate(graphm6)\n",
    "elif country_or_institution_view == \"c\":  # Country-based\n",
    "    grapha1 = graggregate_country(graphm1)\n",
    "    grapha2 = graggregate_country(graphm2)\n",
    "    grapha3 = graggregate_country(graphm3)\n",
    "    grapha4 = graggregate_country(graphm4)\n",
    "    grapha5 = graggregate_country(graphm5)\n",
    "    grapha6 = graggregate_country(graphm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4596e3c2-ed6e-4738-a865-d824bf05f252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_edges(old_graph, new_graph):\n",
    "    # Add a new column 'edge_multiplier' initialized with value 1\n",
    "    new_graph = new_graph.copy()\n",
    "    new_graph['edge_multiplier'] = 1\n",
    "\n",
    "    # Iterate over each row in new_graph\n",
    "    for i, row in new_graph.iterrows():\n",
    "        from_node = row['from']\n",
    "        to_node = row['to']\n",
    "\n",
    "        # Calculate the total weights in old and new graphs for the same edge\n",
    "        old_sum = old_graph.loc[\n",
    "            (old_graph['from'] == from_node) & (old_graph['to'] == to_node), 'weight'\n",
    "        ].sum()\n",
    "        new_sum = new_graph.loc[\n",
    "            (new_graph['from'] == from_node) & (new_graph['to'] == to_node), 'weight'\n",
    "        ].sum()\n",
    "\n",
    "        # Adjust 'edge_multiplier' based on the weight difference\n",
    "        if old_sum != 0:\n",
    "            if new_sum - old_sum > 0:\n",
    "                new_graph.at[i, 'edge_multiplier'] = 2\n",
    "            elif new_sum - old_sum < 0:\n",
    "                new_graph.at[i, 'edge_multiplier'] = 0.5\n",
    "\n",
    "    return new_graph\n",
    "\n",
    "# Apply the function to adjust edge multipliers sequentially\n",
    "grapha1 = adjust_edges(grapha1, grapha1)\n",
    "grapha2 = adjust_edges(grapha1, grapha2)\n",
    "grapha3 = adjust_edges(grapha2, grapha3)\n",
    "grapha4 = adjust_edges(grapha3, grapha4)\n",
    "grapha5 = adjust_edges(grapha4, grapha5)\n",
    "grapha6 = adjust_edges(grapha5, grapha6)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1ddc5c7-c445-481c-a5df-93e67767f379",
   "metadata": {},
   "source": [
    "# More efficient: \n",
    "graphs = [grapha1, grapha2, grapha3, grapha4, grapha5, grapha6]\n",
    "\n",
    "for i in range(1, len(graphs)):\n",
    "    graphs[i] = adjust_edges(graphs[i-1], graphs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83c142f4-0683-4f42-9a45-1f08678b6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Node List. We use the unique() method to extract unique values from the from and to columns. \n",
    "# For country-level aggregation, the relevant columns are from.country and to.country.\n",
    "# The pd.concat() function combines the two DataFrames, and drop_duplicates() ensures all rows remain unique.\n",
    "# NA Handling: The combined DataFrame is filtered to remove any rows with NA values, ensuring that only valid entries are kept.\n",
    "# Data Type: The resulting temp1 column is explicitly converted to string type for consistency.\n",
    "# Sorting the Lists: The resultant DataFrames are sorted by the temp1 column in alphabetical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "108e1853-8921-4aaf-9154-ef97194f6f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temp1(graph):\n",
    "    # Get unique 'from' nodes\n",
    "    temp1 = pd.DataFrame(graph['from'].unique(), columns=['temp1'])\n",
    "    return temp1\n",
    "\n",
    "def create_temp2(graph):\n",
    "    # Use placeholder values if 'from.country' or 'to.country' attributes are missing\n",
    "    from_country = graph['from.country'] if 'from.country' in graph.columns else ['Unknown'] * len(graph)\n",
    "    to_country = graph['to.country'] if 'to.country' in graph.columns else ['Unknown'] * len(graph)\n",
    "    \n",
    "    # Get unique 'from' and 'to' nodes\n",
    "    temp1 = pd.DataFrame(pd.Series(from_country).unique(), columns=['temp1'])\n",
    "    temp2 = pd.DataFrame(pd.Series(to_country).unique(), columns=['temp1'])\n",
    "    \n",
    "    return temp1, temp2\n",
    "\n",
    "# Create temporary lists based on the view type\n",
    "if country_or_institution_view == \"i\":\n",
    "    tempm1 = create_temp1(grapha1)\n",
    "    tempm2 = create_temp1(grapha2)\n",
    "    tempm3 = create_temp1(grapha3)\n",
    "    tempm4 = create_temp1(grapha4)\n",
    "    tempm5 = create_temp1(grapha5)\n",
    "    tempm6 = create_temp1(grapha6)\n",
    "\n",
    "elif country_or_institution_view == \"c\":\n",
    "    tempm1, tempm2 = create_temp2(grapha1)\n",
    "    tempm3, tempm4 = create_temp2(grapha2)\n",
    "    tempm5, tempm6 = create_temp2(grapha3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb4de4ff-643f-41e8-96c1-48fc7d95f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node list (Institution-level)\n",
    "# The create_temp1 function creates a unique list of nodes (from and to) at the institution level, \n",
    "  # while create_temp2 does the same for the country level.\n",
    "def create_temp1(graph):\n",
    "    temp1 = pd.DataFrame(graph['from'].unique(), columns=['temp1'])\n",
    "    temp2 = pd.DataFrame(graph['to'].unique(), columns=['temp1'])\n",
    "    temp1 = pd.concat([temp1, temp2]).drop_duplicates().reset_index(drop=True)\n",
    "    temp1 = temp1[temp1['temp1'].notna()]\n",
    "    return temp1\n",
    "\n",
    "# Create node list (Country-level)\n",
    "def create_temp2(graph):\n",
    "    temp1 = pd.DataFrame(graph['from'].unique(), columns=['temp1'])\n",
    "    temp2 = pd.DataFrame(graph['to'].unique(), columns=['temp1'])\n",
    "    temp1 = pd.concat([temp1, temp2]).drop_duplicates().reset_index(drop=True)\n",
    "    temp1 = temp1[temp1['temp1'].notna()]\n",
    "    return temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "852b2c2c-cc1e-418c-896a-0d5307d95ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge node list with transparency index\n",
    "# Transparency data is merged with the node lists if color_using_index == \"yes\" and the view is country-based.\n",
    "def merge_with_transp(transparency, node_list):\n",
    "    temp = transparency[transparency['Code'].isin(node_list['temp1'])]\n",
    "    temp2 = pd.merge(node_list, temp, how='left', left_on='temp1', right_on='Code').fillna(0)\n",
    "    return temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2c06e5f-953e-4089-b73a-009895683cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create node lists based on toggle\n",
    "if country_or_institution_view == \"i\":\n",
    "    tempm1 = create_temp1(grapha1)\n",
    "    tempm2 = create_temp1(grapha2)\n",
    "    tempm3 = create_temp1(grapha3)\n",
    "    tempm4 = create_temp1(grapha4)\n",
    "    tempm5 = create_temp1(grapha5)\n",
    "    tempm6 = create_temp1(grapha6)\n",
    "elif country_or_institution_view == \"c\":\n",
    "    tempm1 = create_temp2(grapha1)\n",
    "    tempm2 = create_temp2(grapha2)\n",
    "    tempm3 = create_temp2(grapha3)\n",
    "    tempm4 = create_temp2(grapha4)\n",
    "    tempm5 = create_temp2(grapha5)\n",
    "    tempm6 = create_temp2(grapha6)\n",
    "\n",
    "# Sort node lists in alphabetical order\n",
    "tempm1 = tempm1.sort_values('temp1').reset_index(drop=True)\n",
    "tempm2 = tempm2.sort_values('temp1').reset_index(drop=True)\n",
    "tempm3 = tempm3.sort_values('temp1').reset_index(drop=True)\n",
    "tempm4 = tempm4.sort_values('temp1').reset_index(drop=True)\n",
    "tempm5 = tempm5.sort_values('temp1').reset_index(drop=True)\n",
    "tempm6 = tempm6.sort_values('temp1').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3333783b-e4a2-4e47-86ad-418e10fbb70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge node lists with transparency index (if applicable)\n",
    "# Transparency data is merged with the node lists if color_using_index == \"yes\" and the view is country-based.\n",
    "if country_or_institution_view == \"c\" and color_using_index == \"yes\":\n",
    "    tempm1 = merge_with_transp(transparency, tempm1)\n",
    "    tempm2 = merge_with_transp(transparency, tempm2)\n",
    "    tempm3 = merge_with_transp(transparency, tempm3)\n",
    "    tempm4 = merge_with_transp(transparency, tempm4)\n",
    "    tempm5 = merge_with_transp(transparency, tempm5)\n",
    "    tempm6 = merge_with_transp(transparency, tempm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d39a8d17-edde-4585-9e1b-23e2dba174a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate directed networks using NetworkX\n",
    "# Directed graphs (DiGraph) are created for each graph using NetworkX, with edges weighted by weight.\n",
    "def create_network(graph, vertices):\n",
    "    G = nx.DiGraph()\n",
    "    for _, row in graph.iterrows():\n",
    "        G.add_edge(row['from'], row['to'], weight=row['weight'])\n",
    "    nx.set_node_attributes(G, {node: data['temp1'] for node, data in vertices.iterrows()})\n",
    "    return G\n",
    "\n",
    "if country_or_institution_view == \"c\":\n",
    "    networkm1 = create_network(grapha1, tempm1)\n",
    "    networkm2 = create_network(grapha2, tempm2)\n",
    "    networkm3 = create_network(grapha3, tempm3)\n",
    "    networkm4 = create_network(grapha4, tempm4)\n",
    "    networkm5 = create_network(grapha5, tempm5)\n",
    "    networkm6 = create_network(grapha6, tempm6)\n",
    "else:\n",
    "    networkm1 = create_network(grapha1, tempm1)\n",
    "    networkm2 = create_network(grapha2, tempm2)\n",
    "    networkm3 = create_network(grapha3, tempm3)\n",
    "    networkm4 = create_network(grapha4, tempm4)\n",
    "    networkm5 = create_network(grapha5, tempm5)\n",
    "    networkm6 = create_network(grapha6, tempm6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "513d5a2e-f761-4d94-80ea-3cfc1ebc5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate PageRank scores for each network\n",
    "prm1 = nx.pagerank(networkm1)\n",
    "prm2 = nx.pagerank(networkm2)\n",
    "prm3 = nx.pagerank(networkm3)\n",
    "prm4 = nx.pagerank(networkm4)\n",
    "prm5 = nx.pagerank(networkm5)\n",
    "prm6 = nx.pagerank(networkm6)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f1e597c-ae07-49f9-9c65-8cca431045c4",
   "metadata": {},
   "source": [
    "SELECT NETWORK TO PLOT: The correct network (networkm1 to networkm6) is chosen based on the selected_period variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c8efa32f-d1e8-41cb-8cb1-639adccf949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the network based on the selected period\n",
    "if selected_period == 1:\n",
    "    selected_network = networkm1\n",
    "elif selected_period == 2:\n",
    "    selected_network = networkm2\n",
    "elif selected_period == 3:\n",
    "    selected_network = networkm3\n",
    "elif selected_period == 4:\n",
    "    selected_network = networkm4\n",
    "elif selected_period == 5:\n",
    "    selected_network = networkm5\n",
    "elif selected_period == 6:\n",
    "    selected_network = networkm6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "14d8d322-7492-40df-a409-48a91ac1be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholds for quintiles\n",
    "bottom_quintile = 26\n",
    "second_lowest_quintile = 42\n",
    "# Node colors are determined based on the attributes speriod5 and chperiod5, with inside and frame colors applied for the country-level view.\n",
    "if country_or_institution_view == \"c\" and color_using_index == \"yes\":\n",
    "    for node in selected_network.nodes():\n",
    "        speriod5 = selected_network.nodes[node].get('speriod5', 0)\n",
    "        chperiod5 = selected_network.nodes[node].get('chperiod5', 0)\n",
    "        \n",
    "        # Inside (fill) color\n",
    "        if node == selected_country:\n",
    "            selected_network.nodes[node]['color'] = \"white\"\n",
    "        elif 1 < speriod5 < bottom_quintile:\n",
    "            selected_network.nodes[node]['color'] = \"red\"\n",
    "        elif 1 < speriod5 < second_lowest_quintile:\n",
    "            selected_network.nodes[node]['color'] = \"orange\"\n",
    "        else:\n",
    "            selected_network.nodes[node]['color'] = \"gray\"\n",
    "        \n",
    "        # Frame (outline) color\n",
    "        if chperiod5 == \"-1\":\n",
    "            selected_network.nodes[node]['frame_color'] = \"red\"\n",
    "        elif chperiod5 == \"1\":\n",
    "            selected_network.nodes[node]['frame_color'] = \"green\"\n",
    "        else:\n",
    "            selected_network.nodes[node]['frame_color'] = \"black\"\n",
    "elif country_or_institution_view == \"c\" and color_using_index == \"no\":\n",
    "    for node in selected_network.nodes():\n",
    "        selected_network.nodes[node]['color'] = \"white\" if node == \"US\" else \"gray\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e6ab081-3b51-42d4-b96f-1e0caca4827d",
   "metadata": {},
   "source": [
    "VISUALIZE THE NETWORK: The pyvis library is used for interactive and customizable visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "54d998bf-0374-46c2-ab5d-b36bb28d55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade pyvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8198f535-2cb2-4138-a67a-621958261c76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pip install Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbec5fd7-ccc4-4095-b4e8-b698fad62dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe0dd9c6-eef0-4358-b379-0258b9baea41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved network visualization saved as 'improved_network.html'\n"
     ]
    }
   ],
   "source": [
    "# Create a PyVis network for visualization\n",
    "net = Network(height=\"1000px\", width=\"1000px\", directed=True, bgcolor=\"white\", notebook=False)\n",
    "\n",
    "# Enable Physics for better layout spacing\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -20000,\n",
    "      \"centralGravity\": 0.3,\n",
    "      \"springLength\": 95,\n",
    "      \"springConstant\": 0.04\n",
    "    },\n",
    "    \"solver\": \"barnesHut\"\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"dynamic\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Add nodes with attributes\n",
    "pagerank = nx.pagerank(selected_network)  # Calculate PageRank for sizing nodes\n",
    "for node in selected_network.nodes(data=True):\n",
    "    node_id = node[0]\n",
    "    attrs = node[1]\n",
    "    size = np.sqrt(pagerank.get(node_id, 1)) * 70  # Scale size by PageRank\n",
    "    color = attrs.get(\"color\", \"gray\")  # Default color is gray\n",
    "    net.add_node(node_id, title=node_id, color=color, size=size)\n",
    "\n",
    "# Add edges with attributes\n",
    "weights = [d.get(\"weight\", 1) for (_, _, d) in selected_network.edges(data=True)]\n",
    "median_weight = np.median(weights) if weights else 1\n",
    "\n",
    "for edge in selected_network.edges(data=True):\n",
    "    from_node, to_node, attrs = edge\n",
    "    weight = attrs.get(\"weight\", median_weight)\n",
    "    edge_multiplier = attrs.get(\"edge_multiplier\", 1)\n",
    "    color = \"green\" if edge_multiplier == 1 else \"gray\"\n",
    "    width = np.sqrt(weight / median_weight) * 2  # Normalize width\n",
    "    net.add_edge(from_node, to_node, color=color, width=width)\n",
    "\n",
    "# Generate the HTML content\n",
    "html_content = net.generate_html()\n",
    "\n",
    "# Use BeautifulSoup to refine the generated HTML further\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Modify the network visualization's background and interactivity options\n",
    "canvas = soup.find('div', {'id': 'mynetwork'})\n",
    "if canvas:\n",
    "    canvas['style'] = 'background-color: lightblue;'  # Light blue background for aesthetics\n",
    "\n",
    "# Save the refined HTML\n",
    "with open(\"improved_network.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(str(soup))\n",
    "\n",
    "print(\"Improved network visualization saved as 'improved_network.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "11387c1b-5b18-44ce-8b40-4d7ed58f8746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final network visualization saved as 'final_network_visualization.html'\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Generate positions using spring_layout\n",
    "pos = nx.spring_layout(selected_network, k=1.5, iterations=500)\n",
    "\n",
    "# Create PyVis network\n",
    "net = Network(height=\"1500px\", width=\"1500px\", directed=True, bgcolor=\"white\", notebook=False)\n",
    "\n",
    "# Set physics options for node repulsion\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -200000,\n",
    "      \"centralGravity\": 0.01,\n",
    "      \"springLength\": 400,\n",
    "      \"springConstant\": 0.005\n",
    "    },\n",
    "    \"minVelocity\": 0.2\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"curvedCW\",\n",
    "      \"roundness\": 0.2\n",
    "    }\n",
    "  },\n",
    "  \"layout\": {\n",
    "    \"hierarchical\": {\n",
    "      \"enabled\": false\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Detect communities and assign groups to nodes\n",
    "communities = list(greedy_modularity_communities(selected_network))\n",
    "for i, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        selected_network.nodes[node]['group'] = i\n",
    "\n",
    "# Add nodes with positions, sizes, and clustering\n",
    "pagerank = nx.pagerank(selected_network)\n",
    "for node, coords in pos.items():\n",
    "    size = np.sqrt(pagerank.get(node, 1)) * 120  # Scale node size\n",
    "    group = selected_network.nodes[node].get('group', 0)  # Assign group if available\n",
    "    net.add_node(node, x=coords[0] * 1000, y=coords[1] * 1000, size=size, group=group, title=node)\n",
    "\n",
    "# Add edges with filtering and normalization\n",
    "weights = [attr.get(\"weight\", 1) for _, _, attr in selected_network.edges(data=True)]\n",
    "median_weight = np.median(weights) if weights else 1\n",
    "\n",
    "threshold = 0.5  # Filter threshold for edge weights\n",
    "for edge in selected_network.edges(data=True):\n",
    "    from_node, to_node, attr = edge\n",
    "    weight = attr.get(\"weight\", median_weight)\n",
    "    if weight > threshold:  # Include only significant edges\n",
    "        width = max(weight / median_weight, 1) * 2  # Normalize edge width\n",
    "        net.add_edge(from_node, to_node, width=width, color=attr.get(\"color\", \"gray\"))\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "net.write_html(\"final_network_visualization.html\")\n",
    "print(\"Final network visualization saved as 'final_network_visualization.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44576aed-d8ae-408c-88cc-5a6f59a33ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 21\n",
      "Number of edges: 26\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of nodes: {len(filtered_graph.nodes())}\")\n",
    "print(f\"Number of edges: {len(filtered_graph.edges())}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "35af939a-012b-4867-ba0f-f1e2f3d32739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network visualization saved as 'debugged_network.html'\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Filter edges with a relaxed threshold\n",
    "threshold = 0.5\n",
    "filtered_edges = [\n",
    "    (u, v, attr) for u, v, attr in selected_network.edges(data=True) if attr.get(\"weight\", 0) > threshold\n",
    "]\n",
    "filtered_graph = nx.DiGraph()\n",
    "filtered_graph.add_edges_from(filtered_edges)\n",
    "\n",
    "# Ensure there are nodes\n",
    "if len(filtered_graph.nodes()) == 0 or len(filtered_graph.edges()) == 0:\n",
    "    print(\"No nodes or edges to visualize. Lowering threshold.\")\n",
    "    threshold = 0.1  # Adjust threshold to include more edges\n",
    "\n",
    "# Calculate positions\n",
    "pos = nx.spring_layout(filtered_graph, k=1.5, iterations=300)\n",
    "\n",
    "# Create PyVis network\n",
    "net = Network(height=\"1500px\", width=\"1500px\", directed=True, bgcolor=\"white\", notebook=False)\n",
    "\n",
    "# Reset physics settings\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -30000,\n",
    "      \"centralGravity\": 0.3,\n",
    "      \"springLength\": 150,\n",
    "      \"springConstant\": 0.05\n",
    "    },\n",
    "    \"minVelocity\": 0.75\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Add nodes\n",
    "for node, coords in pos.items():\n",
    "    size = 50  # Default size for all nodes\n",
    "    group = 0  # Default group assignment\n",
    "    net.add_node(node, x=coords[0] * 1000, y=coords[1] * 1000, size=size, group=group, title=node)\n",
    "\n",
    "# Add edges\n",
    "for u, v, attr in filtered_graph.edges(data=True):\n",
    "    weight = attr.get(\"weight\", 1)\n",
    "    net.add_edge(u, v, width=max(weight, 1), color=\"gray\")\n",
    "\n",
    "# Save the network visualization\n",
    "net.write_html(\"debugged_network.html\")\n",
    "print(\"Network visualization saved as 'debugged_network.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "13fe8c01-7b93-4ee1-9353-46068b3d4af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: DE, Position: [-0.1633955  -0.02955287]\n",
      "Node: XX, Position: [-0.16340719 -0.02949632]\n",
      "Node: BE, Position: [-0.74566968 -0.55402593]\n",
      "Node: CA, Position: [0.77529597 0.61539905]\n",
      "Node: CH, Position: [0.4191425  0.86185304]\n",
      "Node: CL, Position: [-0.28161696 -0.90101781]\n",
      "Node: CN, Position: [-0.53324403  0.78237014]\n",
      "Node: EC, Position: [ 0.26540387 -0.92738046]\n",
      "Node: ES, Position: [-0.16885109 -0.0302077 ]\n",
      "Node: HK, Position: [-0.88720224  0.10022155]\n",
      "Node: IN, Position: [ 0.74427281 -0.67120634]\n",
      "Node: IT, Position: [-0.03912195  0.93580186]\n",
      "Node: JM, Position: [-0.16353379 -0.02835806]\n",
      "Node: JP, Position: [-0.16264399 -0.03101203]\n",
      "Node: KR, Position: [ 1.         -0.17184169]\n",
      "Node: MX, Position: [0.96222023 0.23042822]\n",
      "Node: PA, Position: [-0.16337713 -0.02951624]\n",
      "Node: US, Position: [-0.16337733 -0.02951312]\n",
      "Node: GB, Position: [-0.21581185 -0.03730018]\n",
      "Node: SC, Position: [-0.15865108 -0.01893418]\n",
      "Node: TW, Position: [-0.15643157 -0.03671097]\n"
     ]
    }
   ],
   "source": [
    "for node, coords in pos.items():\n",
    "    print(f\"Node: {node}, Position: {coords}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b74418f4-f643-4f28-86a2-cdbf0b3dd2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge from DE to XX, Attributes: {'weight': 15856874.0, 'color': 'gray'}\n",
      "Edge from XX to BE, Attributes: {'weight': 3070387.0, 'color': 'gray'}\n",
      "Edge from XX to CA, Attributes: {'weight': 140488.0, 'color': 'gray'}\n",
      "Edge from XX to CH, Attributes: {'weight': 646000.0, 'color': 'gray'}\n",
      "Edge from XX to CL, Attributes: {'weight': 2000000.0, 'color': 'gray'}\n",
      "Edge from XX to CN, Attributes: {'weight': 2769490.0, 'color': 'gray'}\n",
      "Edge from XX to DE, Attributes: {'weight': 31111896.0, 'color': 'gray'}\n",
      "Edge from XX to EC, Attributes: {'weight': 65900.0, 'color': 'gray'}\n",
      "Edge from XX to ES, Attributes: {'weight': 9951066.0, 'color': 'gray'}\n",
      "Edge from XX to HK, Attributes: {'weight': 227179.0, 'color': 'gray'}\n",
      "Edge from XX to IN, Attributes: {'weight': 77690.0, 'color': 'gray'}\n",
      "Edge from XX to IT, Attributes: {'weight': 80000.0, 'color': 'gray'}\n",
      "Edge from XX to JM, Attributes: {'weight': 97579219.0, 'color': 'gray'}\n",
      "Edge from XX to JP, Attributes: {'weight': 3145.0, 'color': 'gray'}\n",
      "Edge from XX to KR, Attributes: {'weight': 761104.0, 'color': 'gray'}\n",
      "Edge from XX to MX, Attributes: {'weight': 722139.0, 'color': 'gray'}\n",
      "Edge from XX to PA, Attributes: {'weight': 13238145.0, 'color': 'gray'}\n",
      "Edge from XX to US, Attributes: {'weight': 6522511700.0, 'color': 'gray'}\n",
      "Edge from ES to XX, Attributes: {'weight': 32283.0, 'color': 'gray'}\n",
      "Edge from JM to XX, Attributes: {'weight': 2513061.0, 'color': 'gray'}\n",
      "Edge from JP to XX, Attributes: {'weight': 806726.0, 'color': 'gray'}\n",
      "Edge from PA to XX, Attributes: {'weight': 101771169.0, 'color': 'gray'}\n",
      "Edge from US to XX, Attributes: {'weight': 8735664098.0, 'color': 'gray'}\n",
      "Edge from GB to XX, Attributes: {'weight': 51.0, 'color': 'gray'}\n",
      "Edge from SC to XX, Attributes: {'weight': 4056.0, 'color': 'gray'}\n",
      "Edge from TW to XX, Attributes: {'weight': 6210.0, 'color': 'gray'}\n"
     ]
    }
   ],
   "source": [
    "for u, v, attr in filtered_graph.edges(data=True):\n",
    "    print(f\"Edge from {u} to {v}, Attributes: {attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f1fc565-0caa-44b6-8586-272cbbd94473",
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, coords in pos.items():\n",
    "    net.add_node(node, x=coords[0] * 1000, y=coords[1] * 1000, size=50, label=node, color=\"blue\")  # Default blue nodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "44ecdcdb-2c47-4d5b-92fe-e289cb213e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced network visualization saved as 'balanced_network_visualization.html'\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "\n",
    "# Step 1: Filter edges aggressively\n",
    "threshold = 1.0  # Adjust threshold for edge weights\n",
    "filtered_edges = [\n",
    "    (u, v, attr) for u, v, attr in selected_network.edges(data=True) if attr.get(\"weight\", 0) > threshold\n",
    "]\n",
    "filtered_graph = nx.DiGraph()\n",
    "filtered_graph.add_edges_from(filtered_edges)\n",
    "\n",
    "# Step 2: Generate positions with more relaxed spacing\n",
    "pos = nx.spring_layout(filtered_graph, k=2.0, iterations=800)\n",
    "\n",
    "# Step 3: Create PyVis network\n",
    "net = Network(height=\"1500px\", width=\"1500px\", directed=True, bgcolor=\"white\", notebook=False)\n",
    "\n",
    "# Step 4: Apply physics for balanced node distribution\n",
    "net.set_options(\"\"\"\n",
    "{\n",
    "  \"physics\": {\n",
    "    \"enabled\": true,\n",
    "    \"barnesHut\": {\n",
    "      \"gravitationalConstant\": -1000000,\n",
    "      \"centralGravity\": 0.0005,\n",
    "      \"springLength\": 500,\n",
    "      \"springConstant\": 0.001\n",
    "    },\n",
    "    \"minVelocity\": 0.1\n",
    "  },\n",
    "  \"edges\": {\n",
    "    \"smooth\": {\n",
    "      \"type\": \"dynamic\",\n",
    "      \"roundness\": 0.3\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Step 5: Add nodes with normalized sizes\n",
    "pagerank = nx.pagerank(filtered_graph)\n",
    "for node, coords in pos.items():\n",
    "    size = max(30, np.sqrt(pagerank.get(node, 1)) * 100)  # Normalize node sizes\n",
    "    net.add_node(node, x=coords[0] * 1000, y=coords[1] * 1000, size=size, label=node, color=\"blue\")\n",
    "\n",
    "# Step 6: Add edges with normalized widths\n",
    "for u, v, attr in filtered_graph.edges(data=True):\n",
    "    weight = attr.get(\"weight\", 1)\n",
    "    net.add_edge(u, v, width=max(weight / 2, 1), color=\"gray\")  # Normalize edge widths\n",
    "\n",
    "# Step 7: Save the visualization\n",
    "net.write_html(\"balanced_network_visualization.html\")\n",
    "print(\"Balanced network visualization saved as 'balanced_network_visualization.html'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8aa250-ae66-424b-8847-4f3b8c8942b9",
   "metadata": {},
   "source": [
    "Conducting a SWIFT network data analysis involves exploring various aspects of\n",
    "connectivity, transaction flow, centrality measures, and visualizations. Below, I will outline\n",
    "several key questions that can be addressed through Python scripts, along with example\n",
    "scripts for each analytical aspect based on the architecture of your data.\n",
    "Key Questions for SWIFT Network Data Analysis\n",
    "1. Who are the central nodes in the network?\n",
    "o Analyze which nodes (countries or institutions) are the most influential\n",
    "based on centrality measures (e.g., degree centrality, betweenness\n",
    "centrality).\n",
    "2. What are the transaction flows between nodes?\n",
    "o Measure the volume and weight of transactions between nodes to identify\n",
    "significant flows.\n",
    "3. How do clusters exist within the network?\n",
    "o Identify communities or clusters within the network to understand how\n",
    "nodes group together.\n",
    "4. What is the distribution of transactions over time?\n",
    "o Analyze how the transaction volume varies over time to identify trends or\n",
    "anomalies.\n",
    "5. Visualize the network with dierent emphasis based on specific metrics.\n",
    "o Create various visualizations to highlight dierent attributes, such as\n",
    "transaction volume or centrality metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa3bc87-a1bf-43a7-8848-a926db7ddf1b",
   "metadata": {},
   "source": [
    "1. Centrality Analysis\n",
    "This script calculates degree centrality and betweenness centrality for nodes in the\n",
    "network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f3341737-6d79-436c-ae90-dc93dd653a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Node  Degree Centrality  Betweenness Centrality\n",
      "1    XX                  1                       0\n",
      "0    DE                  0                       0\n",
      "12   JM                  0                       0\n",
      "17   US                  0                       0\n",
      "16   PA                  0                       0\n",
      "8    ES                  0                       0\n",
      "13   JP                  0                       0\n",
      "19   SC                  0                       0\n",
      "18   GB                  0                       0\n",
      "15   MX                  0                       0\n",
      "14   KR                  0                       0\n",
      "10   IN                  0                       0\n",
      "11   IT                  0                       0\n",
      "9    HK                  0                       0\n",
      "7    EC                  0                       0\n",
      "6    CN                  0                       0\n",
      "5    CL                  0                       0\n",
      "4    CH                  0                       0\n",
      "3    CA                  0                       0\n",
      "2    BE                  0                       0\n",
      "20   TW                  0                       0\n"
     ]
    }
   ],
   "source": [
    "# Assuming selected_network is your graph\n",
    "degree_centrality = nx.degree_centrality(selected_network)\n",
    "betweenness_centrality = nx.betweenness_centrality(selected_network)\n",
    "# Create a DataFrame to store centrality measures\n",
    "centrality_df = pd.DataFrame({\n",
    "'Node': degree_centrality.keys(),\n",
    "'Degree Centrality': degree_centrality.values(),\n",
    "'Betweenness Centrality': betweenness_centrality.values()\n",
    "})\n",
    "# Sort by Degree Centrality\n",
    "centrality_df = centrality_df.sort_values(by='Degree Centrality', ascending=False)\n",
    "print(centrality_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bcf16f-1aa8-4fa7-9b4d-59c5fc1ad29d",
   "metadata": {},
   "source": [
    "2. Transaction Flow Analysis\n",
    "   This script analyzes transaction volumes and weights between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f99232fc-48fe-4948-87f7-38fbeb631c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Source Target     Weight\n",
      "0      DE     XX   15856874\n",
      "1      ES     XX      32283\n",
      "2      GB     XX         51\n",
      "3      JM     XX    2513061\n",
      "4      JP     XX     806726\n",
      "5      PA     XX  101771169\n",
      "6      SC     XX       4056\n",
      "7      TW     XX       6210\n",
      "8      US     XX 8735664098\n",
      "9      XX     BE    3070387\n",
      "10     XX     CA     140488\n",
      "11     XX     CH     646000\n",
      "12     XX     CL    2000000\n",
      "13     XX     CN    2769490\n",
      "14     XX     DE   31111896\n",
      "15     XX     EC      65900\n",
      "16     XX     ES    9951066\n",
      "17     XX     HK     227179\n",
      "18     XX     IN      77690\n",
      "19     XX     IT      80000\n",
      "20     XX     JM   97579219\n",
      "21     XX     JP       3145\n",
      "22     XX     KR     761104\n",
      "23     XX     MX     722139\n",
      "24     XX     PA   13238145\n",
      "25     XX     US 6522511700\n"
     ]
    }
   ],
   "source": [
    "# Assuming edges have attributes 'weight' corresponding to transaction volume\n",
    "transaction_flow = pd.DataFrame(selected_network.edges(data=True), columns=['Source',\n",
    "'Target', 'Attributes'])\n",
    "transaction_flow['Weight'] = transaction_flow['Attributes'].apply(lambda x: x['weight'])\n",
    "# Group by source and target for total transactions\n",
    "flow_summary = transaction_flow.groupby(['Source', 'Target']).agg({'Weight':\n",
    "'sum'}).reset_index()\n",
    "print(flow_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44ceb1-aaa7-4436-b468-25d5899bd50e",
   "metadata": {},
   "source": [
    "3. Community Detection\n",
    "Using the Girvan-Newman method, this script detects communities in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb0728a4-c6e1-42f8-a0e5-4169be153dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Community 1: {'DE'}\n",
      "Community 2: {'IT', 'US', 'ES', 'BE', 'CN', 'KR', 'MX', 'CA', 'JM', 'JP', 'CL', 'EC', 'PA', 'XX', 'HK', 'TW', 'SC', 'IN', 'GB', 'CH'}\n"
     ]
    }
   ],
   "source": [
    "from networkx.algorithms import community\n",
    "# Using Girvan-Newman method for community detection\n",
    "comp = community.girvan_newman(selected_network)\n",
    "# Get the first level of communities\n",
    "first_level_communities = next(comp)\n",
    "# Display communities\n",
    "for idx, comm in enumerate(first_level_communities):\n",
    "    print(f\"Community {idx + 1}: {comm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0164b-0862-406a-b41e-239d5dfbe75f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
